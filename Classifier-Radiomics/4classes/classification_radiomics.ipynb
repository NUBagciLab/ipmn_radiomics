{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "846cb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c38ffe",
   "metadata": {},
   "source": [
    "### Step 1: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e15013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     patient  original_shape_Elongation  original_shape_Flatness  \\\n",
      "0    CAD-196                   0.189256                 0.162140   \n",
      "1     CAD-73                   0.351586                 0.198430   \n",
      "2    CAD-293                   0.334404                 0.150629   \n",
      "3     CAD-34                   0.297753                 0.165886   \n",
      "4    CAD-289                   0.369507                 0.191274   \n",
      "..       ...                        ...                      ...   \n",
      "241   MCF-18                   0.384588                 0.260835   \n",
      "242   MCF-04                   0.422619                 0.306136   \n",
      "243   MCF-20                   0.607026                 0.451363   \n",
      "244   MCF-26                   0.528133                 0.279510   \n",
      "245   MCF-16                   0.496012                 0.343139   \n",
      "\n",
      "     original_shape_LeastAxisLength  original_shape_MajorAxisLength  \\\n",
      "0                         27.055452                      166.864661   \n",
      "1                         28.300023                      142.619904   \n",
      "2                         25.049969                      166.302409   \n",
      "3                         22.905533                      138.080312   \n",
      "4                         28.917226                      151.181968   \n",
      "..                              ...                             ...   \n",
      "241                       50.317645                      192.909557   \n",
      "242                       59.218086                      193.437277   \n",
      "243                       77.230259                      171.104605   \n",
      "244                       51.892365                      185.654814   \n",
      "245                       57.282081                      166.935686   \n",
      "\n",
      "     original_shape_Maximum2DDiameterColumn  \\\n",
      "0                                 71.243789   \n",
      "1                                112.176758   \n",
      "2                                125.397506   \n",
      "3                                118.897742   \n",
      "4                                122.584470   \n",
      "..                                      ...   \n",
      "241                              181.214721   \n",
      "242                              160.640477   \n",
      "243                              176.878421   \n",
      "244                              180.533777   \n",
      "245                              159.717765   \n",
      "\n",
      "     original_shape_Maximum2DDiameterRow  \\\n",
      "0                              43.910174   \n",
      "1                              55.239994   \n",
      "2                              41.968454   \n",
      "3                              39.052156   \n",
      "4                              54.323763   \n",
      "..                                   ...   \n",
      "241                           115.688573   \n",
      "242                           115.204820   \n",
      "243                           126.777855   \n",
      "244                           132.896024   \n",
      "245                           112.688599   \n",
      "\n",
      "     original_shape_Maximum2DDiameterSlice  original_shape_Maximum3DDiameter  \\\n",
      "0                                80.084984                        147.753412   \n",
      "1                                73.054447                        141.307505   \n",
      "2                               127.707315                        138.214454   \n",
      "3                                84.186784                        122.643250   \n",
      "4                               118.376996                        143.071343   \n",
      "..                                     ...                               ...   \n",
      "241                             134.516321                        208.616784   \n",
      "242                             157.223275                        193.344026   \n",
      "243                             168.360178                        185.546711   \n",
      "244                             155.466124                        187.656948   \n",
      "245                             138.703628                        173.326432   \n",
      "\n",
      "     original_shape_MeshVolume  ...  t2_original_glszm_ZoneEntropy  \\\n",
      "0                 21794.844086  ...                       6.730006   \n",
      "1                 27170.841103  ...                       6.226431   \n",
      "2                 44589.112729  ...                       7.103187   \n",
      "3                 22573.045344  ...                       6.803449   \n",
      "4                 57118.329769  ...                       6.923501   \n",
      "..                         ...  ...                            ...   \n",
      "241              328295.773034  ...                       7.348422   \n",
      "242              412237.758837  ...                       6.990153   \n",
      "243              616900.479029  ...                       7.673432   \n",
      "244              475537.848165  ...                       7.459795   \n",
      "245              318599.237195  ...                       7.016816   \n",
      "\n",
      "     t2_original_glszm_ZonePercentage  t2_original_glszm_ZoneVariance  \\\n",
      "0                            0.130926                     4222.357924   \n",
      "1                            0.078942                    21732.259620   \n",
      "2                            0.535496                        7.897241   \n",
      "3                            0.101150                    10117.697535   \n",
      "4                            0.468494                       15.453667   \n",
      "..                                ...                             ...   \n",
      "241                          0.283907                      818.434997   \n",
      "242                          0.148609                    15945.100423   \n",
      "243                          0.306089                      609.046453   \n",
      "244                          0.422398                      104.125519   \n",
      "245                          0.198203                     6740.136892   \n",
      "\n",
      "     t2_original_ngtdm_Busyness  t2_original_ngtdm_Coarseness  \\\n",
      "0                      7.590112                      0.000418   \n",
      "1                     18.820598                      0.000401   \n",
      "2                      1.788182                      0.000620   \n",
      "3                      6.105898                      0.000441   \n",
      "4                      1.480216                      0.000521   \n",
      "..                          ...                           ...   \n",
      "241                    6.154126                      0.000100   \n",
      "242                   27.656390                      0.000080   \n",
      "243                   19.346982                      0.000057   \n",
      "244                    8.803901                      0.000068   \n",
      "245                   22.136460                      0.000112   \n",
      "\n",
      "     t2_original_ngtdm_Complexity  t2_original_ngtdm_Contrast  \\\n",
      "0                      689.233812                    0.048343   \n",
      "1                      253.260876                    0.019641   \n",
      "2                     8048.228222                    0.534031   \n",
      "3                      706.889681                    0.027489   \n",
      "4                    12124.862507                    0.229836   \n",
      "..                            ...                         ...   \n",
      "241                   7797.230867                    0.160216   \n",
      "242                   1839.756564                    0.081358   \n",
      "243                  10574.114199                    0.239577   \n",
      "244                  14203.960452                    0.266763   \n",
      "245                   2152.454103                    0.128896   \n",
      "\n",
      "     t2_original_ngtdm_Strength      volume  label  \n",
      "0                      0.336680   22.011368      1  \n",
      "1                      0.201187   27.402658      0  \n",
      "2                      0.858050   44.997459      3  \n",
      "3                      0.499707   22.779864      0  \n",
      "4                      2.229999   57.624363      3  \n",
      "..                          ...         ...    ...  \n",
      "241                    0.250263   65.790513      2  \n",
      "242                    0.100857   98.964022      1  \n",
      "243                    0.202638  187.495373      1  \n",
      "244                    0.197523  121.357947      2  \n",
      "245                    0.134489   70.275080      3  \n",
      "\n",
      "[231 rows x 217 columns]\n",
      "1    87\n",
      "3    52\n",
      "0    50\n",
      "2    42\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "df_t1 = pd.read_csv('radiomics_t1_dilated.csv')\n",
    "df_t2 = pd.read_csv('radiomics_t2_dilated.csv')\n",
    "df_label = pd.read_csv('label.csv')\n",
    "df_volume = pd.read_csv('volume.csv')\n",
    "\n",
    "#merge label, volume and t2\n",
    "df_t2.columns = ['t2_'+str(col) for col in df_t2.columns]  # add_prefix\n",
    "df_t2 = df_t2.rename(columns={'t2_patient': 'patient'})\n",
    "\n",
    "df_labeled = df_t1.merge(df_t2, on='patient')   #merge t2\n",
    "df_labeled = df_labeled.merge(df_volume, on ='patient')   #merge volume\n",
    "df_labeled = df_labeled.merge(df_label,on = 'patient')   \n",
    "\n",
    "# df_labeled = df_labeled[df_labeled.label<3]\n",
    "df_labeled.drop_duplicates(subset=['patient'],inplace=True)\n",
    "print(df_labeled)\n",
    "print(df_labeled['label'].value_counts())\n",
    "\n",
    "# df_labeled.to_csv('radiomics_labeled.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa6efb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              patient  label  t2_original_shape_Elongation  \\\n",
      "0             CAD-226      3                     -1.438885   \n",
      "1     NU_Patient_0008      0                     -0.509125   \n",
      "2               AHN21      2                     -0.390296   \n",
      "3             CAD-205      2                      0.168286   \n",
      "4             CAD-181      1                      1.280118   \n",
      "..                ...    ...                           ...   \n",
      "226  nyu_Patient_0083      0                      0.009747   \n",
      "227  nyu_Patient_0150      1                      0.256494   \n",
      "228             MCA02      1                      0.061023   \n",
      "229           CAD-252      2                     -0.379709   \n",
      "230           CAD-262      3                     -1.282669   \n",
      "\n",
      "     t2_original_shape_Flatness  t2_original_shape_LeastAxisLength  \\\n",
      "0                     -0.801203                          -0.607752   \n",
      "1                      0.857875                           0.772158   \n",
      "2                      0.814546                           0.698855   \n",
      "3                     -0.926984                          -0.877284   \n",
      "4                     -0.556948                          -0.457611   \n",
      "..                          ...                                ...   \n",
      "226                    0.850428                           1.090732   \n",
      "227                    0.224250                           0.269332   \n",
      "228                    1.191420                           0.786456   \n",
      "229                   -0.859688                          -1.052854   \n",
      "230                   -0.990083                          -0.909146   \n",
      "\n",
      "     t2_original_shape_MajorAxisLength  \\\n",
      "0                             0.627548   \n",
      "1                            -1.033764   \n",
      "2                            -1.149521   \n",
      "3                             1.094893   \n",
      "4                            -0.494541   \n",
      "..                                 ...   \n",
      "226                          -0.215789   \n",
      "227                          -1.115182   \n",
      "228                          -1.499800   \n",
      "229                          -0.149460   \n",
      "230                           1.879281   \n",
      "\n",
      "     t2_original_shape_Maximum2DDiameterColumn  \\\n",
      "0                                     0.158659   \n",
      "1                                    -1.925895   \n",
      "2                                    -0.985681   \n",
      "3                                     0.841767   \n",
      "4                                    -0.088169   \n",
      "..                                         ...   \n",
      "226                                   0.251937   \n",
      "227                                  -0.766420   \n",
      "228                                  -0.295122   \n",
      "229                                   0.284394   \n",
      "230                                   1.277402   \n",
      "\n",
      "     t2_original_shape_Maximum2DDiameterRow  \\\n",
      "0                                 -0.476651   \n",
      "1                                 -0.648520   \n",
      "2                                 -2.087171   \n",
      "3                                  0.345712   \n",
      "4                                  0.291456   \n",
      "..                                      ...   \n",
      "226                               -0.114631   \n",
      "227                               -1.987146   \n",
      "228                               -0.680039   \n",
      "229                               -0.991502   \n",
      "230                                0.547555   \n",
      "\n",
      "     t2_original_shape_Maximum2DDiameterSlice  \\\n",
      "0                                    1.422090   \n",
      "1                                   -0.758521   \n",
      "2                                   -1.292008   \n",
      "3                                    1.207252   \n",
      "4                                   -0.405805   \n",
      "..                                        ...   \n",
      "226                                 -0.083510   \n",
      "227                                 -0.817769   \n",
      "228                                 -1.073113   \n",
      "229                                 -0.081516   \n",
      "230                                  2.152572   \n",
      "\n",
      "     t2_original_shape_Maximum3DDiameter  ...  \\\n",
      "0                               1.068938  ...   \n",
      "1                              -1.183085  ...   \n",
      "2                              -1.122348  ...   \n",
      "3                               0.976174  ...   \n",
      "4                              -0.902886  ...   \n",
      "..                                   ...  ...   \n",
      "226                            -0.321458  ...   \n",
      "227                            -1.138686  ...   \n",
      "228                            -0.884203  ...   \n",
      "229                            -0.499914  ...   \n",
      "230                             2.022766  ...   \n",
      "\n",
      "     original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
      "0                                       -0.553747                    0.545541   \n",
      "1                                        1.250059                   -0.760867   \n",
      "2                                        1.892898                   -0.696789   \n",
      "3                                        0.006629                    0.558056   \n",
      "4                                       -0.384159                    0.386798   \n",
      "..                                            ...                         ...   \n",
      "226                                      0.872128                    0.200059   \n",
      "227                                      0.298598                    0.049707   \n",
      "228                                      0.378309                    0.225566   \n",
      "229                                     -0.472384                    0.360209   \n",
      "230                                     -1.088629                    0.781339   \n",
      "\n",
      "     original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n",
      "0                        -0.373224                     0.341347   \n",
      "1                         0.259810                    -1.011460   \n",
      "2                         1.512598                    -1.295154   \n",
      "3                        -0.603488                     0.511879   \n",
      "4                        -0.429280                     0.107062   \n",
      "..                             ...                          ...   \n",
      "226                       0.036348                    -0.112663   \n",
      "227                       0.505805                    -0.811946   \n",
      "228                      -0.614034                     0.306000   \n",
      "229                       0.291151                    -0.643875   \n",
      "230                      -0.779225                     1.184432   \n",
      "\n",
      "     original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n",
      "0                   0.723660                  -0.071430   \n",
      "1                  -0.833728                  -0.069412   \n",
      "2                  -1.520516                  -0.068337   \n",
      "3                   0.808111                  -0.071412   \n",
      "4                   0.518809                  -0.071157   \n",
      "..                       ...                        ...   \n",
      "226                -0.111987                  -0.071030   \n",
      "227                -0.354378                  -0.070130   \n",
      "228                -0.086346                  -0.070868   \n",
      "229                -0.621830                  -0.070683   \n",
      "230                 0.634611                  -0.071525   \n",
      "\n",
      "     original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n",
      "0                     0.783616                -0.201190   \n",
      "1                     0.058044                 0.104208   \n",
      "2                    -0.244496                -0.086777   \n",
      "3                    -0.266663                 1.068908   \n",
      "4                     0.038395                 0.377742   \n",
      "..                         ...                      ...   \n",
      "226                   0.216506                -0.018530   \n",
      "227                  -0.886055                 0.139960   \n",
      "228                  -0.134388                -0.629088   \n",
      "229                   1.235734                -0.255655   \n",
      "230                  -0.074656                -0.845782   \n",
      "\n",
      "     original_ngtdm_Strength    volume  \n",
      "0                  -0.242818  0.703549  \n",
      "1                  -0.008127 -0.610256  \n",
      "2                  -0.066686 -2.285642  \n",
      "3                  -0.347783 -0.725794  \n",
      "4                  -0.267105  1.108175  \n",
      "..                       ...       ...  \n",
      "226                -0.265139  0.386306  \n",
      "227                -0.273292 -1.883837  \n",
      "228                -0.198694 -1.619272  \n",
      "229                 0.058769 -0.511307  \n",
      "230                -0.330978 -0.095419  \n",
      "\n",
      "[231 rows x 215 columns]\n",
      "1    81\n",
      "0    70\n",
      "3    41\n",
      "2    39\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###Alternative: load labeled df directly\n",
    "df_labeled = pd.read_csv('uvscaling_t.csv')\n",
    "# df_labeled = df_labeled.drop('Unnamed: 0', axis=1)\n",
    "print(df_labeled)\n",
    "print(df_labeled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b584ad0",
   "metadata": {},
   "source": [
    "### Step 2: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c58810bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 108)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.formula.api import ols \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2,f_classif\n",
    "\n",
    "X = df_labeled.iloc[:,2:]\n",
    "Y = df_labeled.label\n",
    "\n",
    "X_selected = SelectKBest(f_classif, k=108).fit_transform(X, Y)\n",
    "# print(X_selected)\n",
    "X_selected.shape\n",
    "# print(X_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764d2b4",
   "metadata": {},
   "source": [
    "### Step 3: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63645b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3f01309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
      "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
      "              max_depth=4, max_leaves=0, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=180, n_jobs=0,\n",
      "              num_class=4, num_parallel_tree=1, objective='multi:softmax', ...)\n"
     ]
    }
   ],
   "source": [
    "# estimator = XGBClassifier(\n",
    "#     objective='multi:softmax',\n",
    "#     num_class=4,\n",
    "#     seed=42\n",
    "# )\n",
    "# parameters = {\n",
    "#     'max_depth': range (2, 10, 1),\n",
    "#     'n_estimators': range(20, 220, 40),\n",
    "#     'learning_rate': [0.1, 0.01, 0.05]\n",
    "# }\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=estimator,\n",
    "#     param_grid=parameters,\n",
    "#     scoring = 'accuracy',\n",
    "#     n_jobs = 10,\n",
    "#     cv = 5,\n",
    "#     verbose=True\n",
    "# )\n",
    "# grid_search.fit(X_selected, Y)\n",
    "\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "282dae9a",
   "metadata": {},
   "source": [
    "### Step 4: Training, testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "616d5cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [3 0 2 0 0 2 0 1 2 2 2 0 3 1 0 1 2 2 0 2 3 1 0 0 0 2 1 1 0 0 2 2 1 2 3 2 0\n",
      " 0 0 2 1 1 1 1 0 0 2]\n",
      "true: [3 0 2 3 0 1 0 3 3 3 2 0 3 1 0 0 2 3 0 0 0 1 1 0 1 2 3 1 0 0 3 2 0 0 3 3 1\n",
      " 0 0 3 0 1 1 1 0 1 1]\n",
      "accuracy = 55.319149%\n",
      "confusion matrix =\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69        18\n",
      "           1       0.55      0.50      0.52        12\n",
      "           2       0.33      1.00      0.50         5\n",
      "           3       0.75      0.25      0.38        12\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.58      0.60      0.52        47\n",
      "weighted avg       0.64      0.55      0.54        47\n",
      "\n",
      "[0.70588235 0.54545455 0.33333333 0.75      ] [0.66666667 0.5        1.         0.25      ] [0.68571429 0.52173913 0.5        0.375     ] [18 12  5 12]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, Y, test_size=.2)\n",
    "bst = XGBClassifier(n_estimators=180, max_depth=4,objective='multi:softmax',num_class=4)\n",
    "# bst = XGBClassifier(n_estimators=20, max_depth=4,objective='multi:softmax',num_class=4)\n",
    "# create model instance\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "bst.fit(X_train_res, y_train_res) # fit model\n",
    "y_pred = bst.predict(X_test) # make predictions\n",
    "y_true = y_test.to_numpy()\n",
    "print('pred:',y_pred)\n",
    "print('true:',y_true)\n",
    "\n",
    "#evaluation\n",
    "# accuracy = np.count_nonzero(y_true-y_pred)/len(y_pred)\n",
    "accuracy = np.mean(y_true == y_pred)\n",
    "print('accuracy = {:%}'.format(accuracy))\n",
    "print('confusion matrix =')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels= ['NRML','LGD','HGD','cancer']).plot()\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n",
    "print(precision, recall, f1, support)\n",
    "# Calculate ROC AUC score for each class\n",
    "# auc = roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "# print(\"ROC AUC score: \", auc)\n",
    "# cm_display = ConfusionMatrixDisplay(cm, display_labels= ['NRML','LGD','HGD']).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbe83803",
   "metadata": {},
   "source": [
    "### Step 5: Validation_Repeated Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f3f1aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.82      0.64        11\n",
      "           1       0.50      0.50      0.50        14\n",
      "           2       0.62      0.45      0.53        11\n",
      "           3       0.75      0.55      0.63        11\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.60      0.58      0.58        47\n",
      "weighted avg       0.59      0.57      0.57        47\n",
      "\n",
      "data size: X train resampling + Xtest =  315\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.574468085106383\n",
      "2 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62        13\n",
      "           1       0.62      0.59      0.61        17\n",
      "           2       0.58      0.78      0.67         9\n",
      "           3       0.33      0.25      0.29         8\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.54      0.56      0.54        47\n",
      "weighted avg       0.56      0.57      0.57        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.574468085106383\n",
      "3 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69        17\n",
      "           1       0.57      0.50      0.53        16\n",
      "           2       0.20      0.33      0.25         6\n",
      "           3       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.51        47\n",
      "   macro avg       0.46      0.45      0.44        47\n",
      "weighted avg       0.53      0.51      0.51        47\n",
      "\n",
      "data size: X train resampling + Xtest =  307\n",
      "current accuracy: 0.5106382978723404\n",
      "mean accuracy till now: 0.5531914893617021\n",
      "4 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69        14\n",
      "           1       0.78      0.44      0.56        16\n",
      "           2       0.44      0.44      0.44         9\n",
      "           3       0.27      0.38      0.32         8\n",
      "\n",
      "    accuracy                           0.53        47\n",
      "   macro avg       0.53      0.51      0.50        47\n",
      "weighted avg       0.58      0.53      0.53        47\n",
      "\n",
      "data size: X train resampling + Xtest =  307\n",
      "current accuracy: 0.5319148936170213\n",
      "mean accuracy till now: 0.5478723404255319\n",
      "5 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.71        13\n",
      "           1       0.65      0.69      0.67        16\n",
      "           2       0.40      0.22      0.29         9\n",
      "           3       0.40      0.44      0.42         9\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.53      0.53      0.52        47\n",
      "weighted avg       0.56      0.57      0.56        47\n",
      "\n",
      "data size: X train resampling + Xtest =  307\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.553191489361702\n",
      "6 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.59        14\n",
      "           1       0.56      0.53      0.55        17\n",
      "           2       0.43      0.60      0.50         5\n",
      "           3       0.55      0.55      0.55        11\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.54      0.56      0.55        47\n",
      "weighted avg       0.56      0.55      0.55        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.5531914893617021\n",
      "mean accuracy till now: 0.5531914893617021\n",
      "7 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62        14\n",
      "           1       0.64      0.53      0.58        17\n",
      "           2       0.75      0.55      0.63        11\n",
      "           3       0.20      0.40      0.27         5\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.55      0.53      0.52        47\n",
      "weighted avg       0.61      0.55      0.57        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.5531914893617021\n",
      "mean accuracy till now: 0.5531914893617021\n",
      "8 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.44      0.58        16\n",
      "           1       0.50      0.64      0.56        14\n",
      "           2       0.23      0.60      0.33         5\n",
      "           3       0.62      0.42      0.50        12\n",
      "\n",
      "    accuracy                           0.51        47\n",
      "   macro avg       0.56      0.52      0.49        47\n",
      "weighted avg       0.63      0.51      0.53        47\n",
      "\n",
      "data size: X train resampling + Xtest =  315\n",
      "current accuracy: 0.5106382978723404\n",
      "mean accuracy till now: 0.5478723404255319\n",
      "9 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76        15\n",
      "           1       0.56      0.62      0.59        16\n",
      "           2       0.57      0.40      0.47        10\n",
      "           3       0.25      0.33      0.29         6\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.54      0.52      0.53        47\n",
      "weighted avg       0.59      0.57      0.58        47\n",
      "\n",
      "data size: X train resampling + Xtest =  307\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.5508274231678487\n",
      "10 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79        22\n",
      "           1       0.62      0.77      0.69        13\n",
      "           2       0.50      0.33      0.40         3\n",
      "           3       0.62      0.56      0.59         9\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.64      0.61      0.62        47\n",
      "weighted avg       0.70      0.70      0.70        47\n",
      "\n",
      "data size: X train resampling + Xtest =  319\n",
      "current accuracy: 0.7021276595744681\n",
      "mean accuracy till now: 0.5659574468085106\n",
      "11 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56        12\n",
      "           1       0.62      0.59      0.61        17\n",
      "           2       1.00      0.75      0.86        12\n",
      "           3       0.33      0.50      0.40         6\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.62      0.61      0.61        47\n",
      "weighted avg       0.66      0.62      0.63        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.6170212765957447\n",
      "mean accuracy till now: 0.5705996131528046\n",
      "12 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67        17\n",
      "           1       0.42      0.42      0.42        12\n",
      "           2       0.57      0.50      0.53         8\n",
      "           3       0.22      0.20      0.21        10\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.46      0.46      0.46        47\n",
      "weighted avg       0.48      0.49      0.48        47\n",
      "\n",
      "data size: X train resampling + Xtest =  323\n",
      "current accuracy: 0.48936170212765956\n",
      "mean accuracy till now: 0.5638297872340425\n",
      "13 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78        11\n",
      "           1       0.67      0.71      0.69        17\n",
      "           2       0.56      0.50      0.53        10\n",
      "           3       0.62      0.56      0.59         9\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.65      0.64      0.65        47\n",
      "weighted avg       0.65      0.66      0.66        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.6595744680851063\n",
      "mean accuracy till now: 0.5711947626841243\n",
      "14 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.75      0.62        12\n",
      "           1       0.58      0.48      0.52        23\n",
      "           2       0.40      0.33      0.36         6\n",
      "           3       0.17      0.17      0.17         6\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.42      0.43      0.42        47\n",
      "weighted avg       0.49      0.49      0.48        47\n",
      "\n",
      "data size: X train resampling + Xtest =  279\n",
      "current accuracy: 0.48936170212765956\n",
      "mean accuracy till now: 0.5653495440729482\n",
      "15 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.50      0.36         8\n",
      "           1       0.57      0.38      0.46        21\n",
      "           2       0.56      0.56      0.56         9\n",
      "           3       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.50      0.53      0.50        47\n",
      "weighted avg       0.53      0.49      0.49        47\n",
      "\n",
      "data size: X train resampling + Xtest =  295\n",
      "current accuracy: 0.48936170212765956\n",
      "mean accuracy till now: 0.5602836879432623\n",
      "16 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.75      0.60      0.67        15\n",
      "           2       0.60      0.75      0.67         8\n",
      "           3       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.63      0.63      0.62        47\n",
      "weighted avg       0.66      0.66      0.65        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.6595744680851063\n",
      "mean accuracy till now: 0.5664893617021276\n",
      "17 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69        15\n",
      "           1       0.85      0.61      0.71        18\n",
      "           2       0.29      0.33      0.31         6\n",
      "           3       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.57      0.58      0.57        47\n",
      "weighted avg       0.65      0.62      0.63        47\n",
      "\n",
      "data size: X train resampling + Xtest =  299\n",
      "current accuracy: 0.6170212765957447\n",
      "mean accuracy till now: 0.5694618272841051\n",
      "18 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67        16\n",
      "           1       0.80      0.50      0.62        16\n",
      "           2       0.38      0.62      0.48         8\n",
      "           3       0.30      0.43      0.35         7\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.55      0.54      0.53        47\n",
      "weighted avg       0.63      0.55      0.57        47\n",
      "\n",
      "data size: X train resampling + Xtest =  307\n",
      "current accuracy: 0.5531914893617021\n",
      "mean accuracy till now: 0.5685579196217493\n",
      "19 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69        16\n",
      "           1       0.67      0.50      0.57        16\n",
      "           2       0.44      0.80      0.57         5\n",
      "           3       0.40      0.40      0.40        10\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.55      0.60      0.56        47\n",
      "weighted avg       0.59      0.57      0.57        47\n",
      "\n",
      "data size: X train resampling + Xtest =  307\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.5688689809630458\n",
      "20 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.62        19\n",
      "           1       0.56      0.53      0.55        17\n",
      "           2       0.17      0.14      0.15         7\n",
      "           3       0.40      0.50      0.44         4\n",
      "\n",
      "    accuracy                           0.51        47\n",
      "   macro avg       0.43      0.45      0.44        47\n",
      "weighted avg       0.50      0.51      0.51        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.5106382978723404\n",
      "mean accuracy till now: 0.5659574468085106\n",
      "21 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.77        13\n",
      "           1       0.58      0.47      0.52        15\n",
      "           2       0.71      0.42      0.53        12\n",
      "           3       0.40      0.57      0.47         7\n",
      "\n",
      "    accuracy                           0.60        47\n",
      "   macro avg       0.59      0.59      0.57        47\n",
      "weighted avg       0.61      0.60      0.58        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.5957446808510638\n",
      "mean accuracy till now: 0.5673758865248226\n",
      "22 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75        18\n",
      "           1       0.69      0.82      0.75        11\n",
      "           2       0.50      0.44      0.47         9\n",
      "           3       0.42      0.56      0.48         9\n",
      "\n",
      "    accuracy                           0.64        47\n",
      "   macro avg       0.62      0.62      0.61        47\n",
      "weighted avg       0.67      0.64      0.64        47\n",
      "\n",
      "data size: X train resampling + Xtest =  327\n",
      "current accuracy: 0.6382978723404256\n",
      "mean accuracy till now: 0.5705996131528046\n",
      "23 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         9\n",
      "           1       0.64      0.58      0.61        24\n",
      "           2       0.50      0.40      0.44         5\n",
      "           3       0.33      0.33      0.33         9\n",
      "\n",
      "    accuracy                           0.53        47\n",
      "   macro avg       0.49      0.50      0.49        47\n",
      "weighted avg       0.54      0.53      0.53        47\n",
      "\n",
      "data size: X train resampling + Xtest =  291\n",
      "current accuracy: 0.5319148936170213\n",
      "mean accuracy till now: 0.5689176688251618\n",
      "24 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85        14\n",
      "           1       0.50      0.53      0.52        15\n",
      "           2       0.50      0.44      0.47         9\n",
      "           3       0.27      0.33      0.30         9\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.55      0.52      0.53        47\n",
      "weighted avg       0.58      0.55      0.56        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.5531914893617021\n",
      "mean accuracy till now: 0.5682624113475176\n",
      "25 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.75        23\n",
      "           1       0.44      0.40      0.42        10\n",
      "           2       0.30      0.50      0.37         6\n",
      "           3       0.45      0.62      0.53         8\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.52      0.54      0.52        47\n",
      "weighted avg       0.64      0.57      0.59        47\n",
      "\n",
      "data size: X train resampling + Xtest =  331\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.5685106382978723\n",
      "26 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68        18\n",
      "           1       0.41      0.50      0.45        14\n",
      "           2       0.50      0.38      0.43         8\n",
      "           3       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.51        47\n",
      "   macro avg       0.45      0.44      0.44        47\n",
      "weighted avg       0.49      0.51      0.50        47\n",
      "\n",
      "data size: X train resampling + Xtest =  315\n",
      "current accuracy: 0.5106382978723404\n",
      "mean accuracy till now: 0.5662847790507365\n",
      "27 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.67      0.56      0.61        18\n",
      "           2       0.33      0.57      0.42         7\n",
      "           3       0.45      0.50      0.48        10\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.59      0.57      0.57        47\n",
      "weighted avg       0.63      0.57      0.59        47\n",
      "\n",
      "data size: X train resampling + Xtest =  299\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.5665878644602048\n",
      "28 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        17\n",
      "           1       0.82      0.47      0.60        19\n",
      "           2       0.38      0.43      0.40         7\n",
      "           3       0.12      0.25      0.17         4\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.50      0.49      0.48        47\n",
      "weighted avg       0.65      0.57      0.59        47\n",
      "\n",
      "data size: X train resampling + Xtest =  295\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.5668693009118541\n",
      "29 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.56      0.50         9\n",
      "           1       0.57      0.57      0.57        21\n",
      "           2       0.45      0.45      0.45        11\n",
      "           3       0.25      0.17      0.20         6\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.43      0.44      0.43        47\n",
      "weighted avg       0.48      0.49      0.48        47\n",
      "\n",
      "data size: X train resampling + Xtest =  291\n",
      "current accuracy: 0.48936170212765956\n",
      "mean accuracy till now: 0.5641966250917094\n",
      "30 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        14\n",
      "           1       0.67      0.67      0.67        15\n",
      "           2       0.50      0.43      0.46         7\n",
      "           3       0.70      0.64      0.67        11\n",
      "\n",
      "    accuracy                           0.68        47\n",
      "   macro avg       0.65      0.65      0.65        47\n",
      "weighted avg       0.67      0.68      0.68        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.6808510638297872\n",
      "mean accuracy till now: 0.5680851063829787\n",
      "31 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        12\n",
      "           1       0.54      0.58      0.56        12\n",
      "           2       0.50      0.47      0.48        15\n",
      "           3       0.40      0.50      0.44         8\n",
      "\n",
      "    accuracy                           0.53        47\n",
      "   macro avg       0.53      0.53      0.53        47\n",
      "weighted avg       0.54      0.53      0.54        47\n",
      "\n",
      "data size: X train resampling + Xtest =  323\n",
      "current accuracy: 0.5319148936170213\n",
      "mean accuracy till now: 0.5669183253260123\n",
      "32 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.71        17\n",
      "           1       0.76      0.76      0.76        17\n",
      "           2       0.71      0.71      0.71         7\n",
      "           3       0.42      0.83      0.56         6\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.70      0.73      0.69        47\n",
      "weighted avg       0.76      0.70      0.71        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.7021276595744681\n",
      "mean accuracy till now: 0.5711436170212766\n",
      "33 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76        14\n",
      "           1       0.67      0.38      0.48        16\n",
      "           2       0.40      0.25      0.31         8\n",
      "           3       0.39      0.78      0.52         9\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.55      0.55      0.52        47\n",
      "weighted avg       0.59      0.55      0.54        47\n",
      "\n",
      "data size: X train resampling + Xtest =  307\n",
      "current accuracy: 0.5531914893617021\n",
      "mean accuracy till now: 0.5705996131528046\n",
      "34 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.38      0.40        13\n",
      "           1       0.29      0.33      0.31        12\n",
      "           2       0.20      0.29      0.24         7\n",
      "           3       0.45      0.33      0.38        15\n",
      "\n",
      "    accuracy                           0.34        47\n",
      "   macro avg       0.34      0.33      0.33        47\n",
      "weighted avg       0.36      0.34      0.35        47\n",
      "\n",
      "data size: X train resampling + Xtest =  323\n",
      "current accuracy: 0.3404255319148936\n",
      "mean accuracy till now: 0.5638297872340425\n",
      "35 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.69      0.56        13\n",
      "           1       0.50      0.47      0.48        15\n",
      "           2       0.56      0.50      0.53        10\n",
      "           3       0.80      0.44      0.57         9\n",
      "\n",
      "    accuracy                           0.53        47\n",
      "   macro avg       0.58      0.53      0.54        47\n",
      "weighted avg       0.56      0.53      0.53        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.5319148936170213\n",
      "mean accuracy till now: 0.562917933130699\n",
      "36 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71        13\n",
      "           1       0.67      0.67      0.67        15\n",
      "           2       0.43      0.27      0.33        11\n",
      "           3       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.53      0.54      0.53        47\n",
      "weighted avg       0.56      0.57      0.56        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.563238770685579\n",
      "37 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        13\n",
      "           1       0.73      0.58      0.65        19\n",
      "           2       0.44      0.67      0.53         6\n",
      "           3       0.67      0.44      0.53         9\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.64      0.65      0.63        47\n",
      "weighted avg       0.68      0.66      0.65        47\n",
      "\n",
      "data size: X train resampling + Xtest =  295\n",
      "current accuracy: 0.6595744680851063\n",
      "mean accuracy till now: 0.5658424381828636\n",
      "38 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        17\n",
      "           1       0.61      0.61      0.61        18\n",
      "           2       0.60      0.38      0.46         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.60        47\n",
      "   macro avg       0.48      0.45      0.46        47\n",
      "weighted avg       0.59      0.60      0.59        47\n",
      "\n",
      "data size: X train resampling + Xtest =  299\n",
      "current accuracy: 0.5957446808510638\n",
      "mean accuracy till now: 0.566629339305711\n",
      "39 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.90      0.62        10\n",
      "           1       0.80      0.36      0.50        22\n",
      "           2       0.18      0.40      0.25         5\n",
      "           3       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.51      0.52      0.46        47\n",
      "weighted avg       0.62      0.49      0.49        47\n",
      "\n",
      "data size: X train resampling + Xtest =  287\n",
      "current accuracy: 0.48936170212765956\n",
      "mean accuracy till now: 0.5646481178396071\n",
      "40 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69        11\n",
      "           1       0.75      0.52      0.62        23\n",
      "           2       0.25      0.60      0.35         5\n",
      "           3       0.50      0.25      0.33         8\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.53      0.55      0.50        47\n",
      "weighted avg       0.62      0.55      0.56        47\n",
      "\n",
      "data size: X train resampling + Xtest =  283\n",
      "current accuracy: 0.5531914893617021\n",
      "mean accuracy till now: 0.5643617021276595\n",
      "41 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        14\n",
      "           1       0.50      0.41      0.45        17\n",
      "           2       0.29      0.40      0.33         5\n",
      "           3       0.50      0.55      0.52        11\n",
      "\n",
      "    accuracy                           0.51        47\n",
      "   macro avg       0.48      0.50      0.49        47\n",
      "weighted avg       0.52      0.51      0.51        47\n",
      "\n",
      "data size: X train resampling + Xtest =  303\n",
      "current accuracy: 0.5106382978723404\n",
      "mean accuracy till now: 0.5630513751946029\n",
      "42 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84        14\n",
      "           1       0.76      0.72      0.74        18\n",
      "           2       0.50      0.50      0.50         8\n",
      "           3       0.20      0.14      0.17         7\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.56      0.57      0.56        47\n",
      "weighted avg       0.64      0.66      0.64        47\n",
      "\n",
      "data size: X train resampling + Xtest =  299\n",
      "current accuracy: 0.6595744680851063\n",
      "mean accuracy till now: 0.5653495440729482\n",
      "43 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71        16\n",
      "           1       0.87      0.62      0.72        21\n",
      "           2       0.43      0.75      0.55         4\n",
      "           3       0.40      0.67      0.50         6\n",
      "\n",
      "    accuracy                           0.66        47\n",
      "   macro avg       0.61      0.68      0.62        47\n",
      "weighted avg       0.72      0.66      0.67        47\n",
      "\n",
      "data size: X train resampling + Xtest =  287\n",
      "current accuracy: 0.6595744680851063\n",
      "mean accuracy till now: 0.5675408213755566\n",
      "44 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67        13\n",
      "           1       0.61      0.61      0.61        18\n",
      "           2       0.38      0.38      0.38         8\n",
      "           3       0.20      0.25      0.22         8\n",
      "\n",
      "    accuracy                           0.51        47\n",
      "   macro avg       0.48      0.46      0.47        47\n",
      "weighted avg       0.53      0.51      0.52        47\n",
      "\n",
      "data size: X train resampling + Xtest =  299\n",
      "current accuracy: 0.5106382978723404\n",
      "mean accuracy till now: 0.5662475822050289\n",
      "45 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60        18\n",
      "           1       0.64      0.60      0.62        15\n",
      "           2       0.29      0.57      0.38         7\n",
      "           3       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.56      0.56      0.54        47\n",
      "weighted avg       0.62      0.55      0.57        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.5531914893617021\n",
      "mean accuracy till now: 0.5659574468085106\n",
      "46 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        13\n",
      "           1       0.50      0.53      0.52        15\n",
      "           2       0.38      0.38      0.38         8\n",
      "           3       0.50      0.45      0.48        11\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.56      0.55      0.55        47\n",
      "weighted avg       0.57      0.57      0.57        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.5661424606845512\n",
      "47 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.75      0.63        16\n",
      "           1       0.42      0.42      0.42        12\n",
      "           2       0.60      0.33      0.43         9\n",
      "           3       0.38      0.30      0.33        10\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.48      0.45      0.45        47\n",
      "weighted avg       0.49      0.49      0.47        47\n",
      "\n",
      "data size: X train resampling + Xtest =  323\n",
      "current accuracy: 0.48936170212765956\n",
      "mean accuracy till now: 0.5645088275237663\n",
      "48 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77        16\n",
      "           1       0.63      0.67      0.65        18\n",
      "           2       0.50      0.57      0.53         7\n",
      "           3       0.20      0.17      0.18         6\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.53      0.54      0.53        47\n",
      "weighted avg       0.61      0.62      0.61        47\n",
      "\n",
      "data size: X train resampling + Xtest =  299\n",
      "current accuracy: 0.6170212765957447\n",
      "mean accuracy till now: 0.5656028368794325\n",
      "49 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72        13\n",
      "           1       0.68      0.62      0.65        21\n",
      "           2       0.25      0.33      0.29         6\n",
      "           3       0.38      0.43      0.40         7\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.51      0.52      0.51        47\n",
      "weighted avg       0.60      0.57      0.59        47\n",
      "\n",
      "data size: X train resampling + Xtest =  287\n",
      "current accuracy: 0.574468085106383\n",
      "mean accuracy till now: 0.5657837603126356\n",
      "50 th trial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45        14\n",
      "           1       0.47      0.47      0.47        15\n",
      "           2       0.40      0.22      0.29         9\n",
      "           3       0.50      0.56      0.53         9\n",
      "\n",
      "    accuracy                           0.45        47\n",
      "   macro avg       0.44      0.44      0.43        47\n",
      "weighted avg       0.44      0.45      0.44        47\n",
      "\n",
      "data size: X train resampling + Xtest =  311\n",
      "current accuracy: 0.44680851063829785\n",
      "mean accuracy till now: 0.5634042553191488\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "a = 0\n",
    "n = 50\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list=[]\n",
    "support_list=[]\n",
    "for i in range(1,n+1):\n",
    "    print(i,'th trial:')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, Y, test_size=.2)\n",
    "\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "    # bst = XGBClassifier(n_estimators=20, objective='multi:softmax',num_class=4)\n",
    "    bst = XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "                colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "                early_stopping_rounds=None, enable_categorical=False,\n",
    "                eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
    "                grow_policy='depthwise', importance_type=None,\n",
    "                interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
    "                max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
    "                max_depth=4, max_leaves=0, min_child_weight=1, \n",
    "                monotone_constraints='()', n_estimators=180, n_jobs=0,\n",
    "                num_class=4, num_parallel_tree=1, objective='multi:softmax') #for 108 features\n",
    "    # bst = XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "    #           colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "    #           early_stopping_rounds=None, enable_categorical=False,\n",
    "    #           eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
    "    #           grow_policy='depthwise', importance_type=None,\n",
    "    #           interaction_constraints='', learning_rate=0.05, max_bin=256,\n",
    "    #           max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
    "    #           max_depth=2, max_leaves=0, min_child_weight=1, \n",
    "    #           monotone_constraints='()', n_estimators=140, n_jobs=0,\n",
    "    #           num_class=4, num_parallel_tree=1, objective='multi:softmax')  # for 50 features\n",
    "    # bst = XGBClassifier(n_estimators=180, max_depth=4,objective='multi:softmax',num_class=4)\n",
    "    # bst = XGBClassifier(n_estimators=20, max_depth=4,objective='multi:softmax',num_class=4)\n",
    "\n",
    "    bst.fit(X_train_res, y_train_res)\n",
    "    y_pred = bst.predict(X_test)\n",
    "    y_true = y_test.to_numpy()\n",
    "    # accuracy = np.count_nonzero(y_true-y_pred)/len(y_pred)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "\n",
    "    # Calculate classification report containing precision, recall, and F1 score for each class\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n",
    "\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    support_list.append(support)\n",
    "\n",
    "    s+=accuracy\n",
    "    print('data size: X train resampling + Xtest = ',len(y_train_res)+len(y_test))\n",
    "    print('current accuracy:',accuracy)\n",
    "    print('mean accuracy till now:',s/i)\n",
    "    # print('mean auc:', a/i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a348c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.5634042553191488\n",
      "labels: 0 1 2 3\n",
      "Mean precision: [0.66884711 0.61766977 0.45298735 0.40964646]\n",
      "Mean recall: [0.70553776 0.55240368 0.46855339 0.42175974]\n",
      "Mean f1: [0.67668668 0.57645406 0.44427322 0.40414297]\n"
     ]
    }
   ],
   "source": [
    "print('Mean accuracy:',s/n)\n",
    "print('labels: 0 1 2 3')\n",
    "print('Mean precision:',np.mean(np.array(precision_list),axis=0))\n",
    "print('Mean recall:',np.mean(np.array(recall_list),axis=0))\n",
    "print('Mean f1:',np.mean(np.array(f1_list),axis=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
